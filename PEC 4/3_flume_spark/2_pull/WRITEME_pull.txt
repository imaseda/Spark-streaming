1. ¿Que componentes habéis utilizado en la configuración del agente de Flume? (Describid brevemente estos componentes)

En el ejercicio anterior hemos hecho una descripción de los componentes, para no ser redundante no repetiré lo mismo, me remito al archivo PEC4_imaseda/3_flume_spark/1_push/WRITEME_push.txt.

2. ¿Que parámetros de estos componentes habéis seleccionado? ¿Cuál es el motivo de vuestra elección y que efecto tienen sus valores en funcionamiento de la aplicación?

En el caso de source y channel, los parametros son los mismos que en el caso anterior (PEC4_imaseda/3_flume_spark/1_push/WRITEME_push.txt). 
En el caso del sink, definiré dos sinks de nuevo, uno para guardar los archivos de tipo hdfs que tendrá la misma configuración explicada en el anterior caso y un nuevo sink que nos permita implementar el modelo de comunicación pull, en este modelo es el proceso Spark Streaming quien, de manera periódica, inicia una comunicación con el agente de Flume para obtener los eventos que aún no ha procesado. En los enlaces de guía de la documentación vemos que debe ser de tipo "org.apache.spark.streaming.flume.sink.SparkSink", que nos permite aplicar la función "FlumeUtils.createPollingStream(ssc, address, maxBatchSize=10, parallelism=2)" en spark streaming, siendo scc StreamingContext(SparkContext, periodo para la comunicación), address el par host/puerto al que se solicitará dicha información,  parallelism=2 ya que hemos definido nuestro StreamingContext con 2 hilos y maxBatchSize=10, para que no se produzcan solicitudes en las que no se envíen lotes de eventos, misma lógica comentada en el modelo push, pero esta vez lo configuramos en la función no en flume.conf. Debemos definir obligattoriamente:
• channel: El canal definido en los componentes del que obtendrá información spark streaming de forma periodica (5 segundos en nuestro caso)
• type: org.apache.spark.streaming.flume.sink.SparkSink, tipo necesario para el modelo pull. 
• hostname: localhost para canalizar la iunformación en el propio host. 
• port: puerto a través del cual se canalizarán los datos para su posterior procesado o guardado. 

Al igual que en el apartado anterior sería posible definir más parámetros a nivel de conexión (connection time-out, request time-out, reset connection interval...), compresión, truststore...Pero para las necesidades del ejercicio bastará con los parámetros definidos, cada 5 segundos spark streaming se encargará de solicitar la información guardada en el canal y procesarla, devolviendo por pantalla los datos agregados en cada "iteración" (por llamarlo de alguna manera), es decir, irá acumulando el número de hashtags presentes en los tweets procesados, mientras que el sumidero tipo hdfs irá guardando cada uno de los tweets recibidos en el directorio seleccionado (con la estructura y tipo seleccionado). Los conceptos fundamentales del recorrido del flujo de datos con flume quedan definidos, desde que solicitamos datos a la API de twitter, estos son almacenados en un canal y canalizados por los sumideros hasta que son almacenados o consumidos por spark streaming para operar con ellos, eliminando los datos de los canales por lotes definidos (o por tiempo) cuando estos son consumidos. Dependiedno del volumen de datos recibido o las limitaciones de hardware (memoria volatil, física...) sería necesario ser más cuidadosos con los parámetros elegidos y sus valores, en este caso, y tras hacer muchas pruebas en el último ejercicio no se procesan más de 100 tweets (entre 20 y 70) cada 5 segundos y la configuración permite que todo el flujo sea estable, no estamos perdiendo información ni saturando hdfs. 

3. ¿Cuales son las ventajas e inconvenientes de cada uno de los modelos de comunicación que habéis estudiado? ¿Cuál es, a vuestro juicio, el que mejor se adapta a los requisitos de esta actividad? (Justificad las respuestas)

En el propio enunciado del ejercicio hemos visto la diferencia entre los dos modelos:

• push: en esté tipo de arquitectura, es obligación del agente Flume enviar al proceso Spark los eventos cuando estos estén disponibles.
• pull: en este modelo de comunicación es el proceso Spark Streaming quien, de manera periódica, inicia una comunicación con el agente de Flume para obtener los eventos que aún no ha procesado.

Para entender las ventajas e inconvenientes presentaré algunos escenarios que pueden darse y los problemas que pueden surgir:

    1. Productor rápido y consumidor lento: Esto puede deberse a que la eficiencia del productor es mayor que la del consumidor (por ejemplo, un procesamiento complejo de los datos por parte del consumidor que requiera más tiempo o involucre cargas de disco, tráfico de red, operaciones entrada/salida...) o fallos en el consumidor que vean interrumpidos los procesos.
En este caso, el modelo push no es capaz de conocer el estado del consumidor (Excepto que se configuren mecanismos adecuados para ello), en principio continuará enviando datos de forma continua llegando incluso a colapsar al consumidor (por ejemplo, el productor es Flume, que recopila una gran cantidad de registros, y el consumidor es HDFS + Hadoop, que está por detrás del productor en cuanto a eficiencia de procesamiento). En cuanto al modelo pull, podemos tener un control más sencillo de este problema, si el tiempo necesario por el consumidor es mayor bastará con reducir los intervalos de acceso por parte de este.

    2. Necesidad de datos en tiempo real: En el modelo push podemos hacer que cada evento sea enviado al consumidor según llegue, acercandonos mucho a un flujo en tiempo real, mientras que en el modelo pull deberíamos configurar el consumidor para hacer peticiones casi de forma continua, no tendría mucho sentido.

    3. Tiempos largos en la obtención de datos en el modelo pull: El consumidor no puede determinar exactamente cuándo se han producido nuevos mensajes, por tanto, si al hacer la solicitud no hay nuevos mensajes deberá esperar un período de tiempo para hacer una nueva solicitud. Existen algoritmos de ajuste del intervalo de extracción dinámica para determinar el tiempo de espera o mecanismos llamados "long polling" que en lugar de devolver un error esperan a que el servidor reciba un nuevo mensaje para hacer una solicitud.
    
    4. Parte o todos los consumidores offline: Existen diferentes motivos por los que un consumidor puede quedar fuera de servicio, si el periodo de tiempo es corto no sería un problema, el productor continua su trabajo y el consumidor continuará con el último mensaje cuándo este en línea, pero si el tiempo es prolongado se deberán abordar problemas como si deben retenerse datos para el consumidor y cuánto tiempo deben retenerse. En el modelo push es imposible predecir si el consumidor estará fuera de servicio y los datos se irán acumulando, esto puede provocar un problema si el volumen es demasiado grande, incluso llegar a perder información si esta no se guarda correctamente, para esto se suele configurar un tiempo de espera para que los datos sean eliminados. El modelo pull mejora esta situación, el servidor proporciona servicios solo cuándo el consumidor se comunica activamente con él, al no ser constante el flujo de datos permite manejar mejor el flujo de datos en ciertas situaciones.
    
En esta actividad el flujo de datos no es suficientemente elevado como para saturar al consumidor, incluso cambiando maxBatchSize=1000 (no he probado más) es capaz de procesarlo en el periodo de 5 segundos (1000 tweets), pero estaríamos actualizando nuestra información cuándo el lote llegue a 1000 tweets y tendríamos muchas solicitudes sin nueva información, ambas soluciones nos ofrecen resultados similares, incluso si detenemos los consumidores durante unos segundos vemos que los tweets no consumidos se acumulan y al volver a acumularse si hacemos un pprint() de kvs.count() (kvs en mi caso) aparece un número elevado (200, 300... depende del tiempo de espera y hasta un límite fijado), obviamente depende de la configuración del número de eventos que puede acumular, memoria...En producción suele ser recomendable emplear métodos pull ya que son más confiables, en caso de que el consumidor se quede "rezagado" puede ponerse al día cuándo el volumen sea menor, y configurandolo correctamente podemos obtener la evolución cada 5 segundos casi en tiempo real, por tanto, creo que ambas opciones son posibles, pero optaré por el modelo pull ya que nos permite controlar mejor el flujo de datos.
