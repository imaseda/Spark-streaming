# Spark-streaming

## Descripción:

Encontramos dos proyectos acedémicos diferenciados:

- 1.Procesamiento en streaming con Apache Flume y Spark (PEC 4): Introducir	algunos	de	los	conceptos	y	funcionalidades	de	la librería	de	streaming	de Spark,
creando flujos de datos con netcat, capturar y organizar streams de	datos (twitter API), combinar FLume y Spark streaming para analizar los hashtags más utilizados, probando las
diferentes configuraciones de comunicación entre ambos que nos ofrece (push y pull) y aplicar un análisis de sentimientos al streaming de tweets (hashtags y tweets completos)
mediante la librería TextBlob.
- 2.Procesamiento de streams de datos con Apache Spark Structured Streaming (PEC 5): Está práctica está formada por dos bloques, uno relacionado con el uso de Kafka y otro centrado en Spark Structured Streaming, probando las diferentes configuraciones que nos ofrece, gestionando el retraso en los flujos de datos, entendiendo el uso de 
triggers y watermarks y entender el concepto de incremental learning.

## Autor
Iván Maseda Zurdo
